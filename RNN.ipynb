{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STCS2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngis1Nw0_Da9"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ658h0Hlyr0"
      },
      "source": [
        "Data preprocessing, converting to numpy array and dividing into train, test, validation dataset. Data location of both glove matrix and sentiment(2) has to be changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR-lI_EvB7uh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQThwALe-TCW"
      },
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/sentiment (2).csv') #change the value to your file location while running\n",
        "print (df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV01z2XJ_LDH"
      },
      "source": [
        "reviews = df['review']\n",
        "labels = np.array(df['senti_score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U_heEDS_KXl"
      },
      "source": [
        "for label in range(len(labels)):\n",
        "  if float(labels[label])<=0.2:\n",
        "    labels[label] = 0\n",
        "  elif float(labels[label])<=0.4:\n",
        "    labels[label] = 1\n",
        "  elif float(labels[label])<=0.6:\n",
        "    labels[label] = 2\n",
        "  elif float(labels[label])<=0.8:\n",
        "    labels[label] = 3\n",
        "  elif float(labels[label])<=1.0:\n",
        "    labels[label] = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySslpYGA-SDo"
      },
      "source": [
        "reviews = reviews.str.lower()\n",
        "for i in range(df.shape[0]):\n",
        "  reviews[i] = re.sub(r'[^\\w\\s]', '', reviews[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laruXhPwAUB-"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/drive/MyDrive/glove.6B.100d.txt', encoding=\"utf8\")   #change the value to your file location while running\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuZ3OYxfd6nG"
      },
      "source": [
        "maxlen = 32 #length of review set here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijmkjH2jAifK"
      },
      "source": [
        "embedding_matrix = np.empty((len(reviews),maxlen,100))\n",
        "j=0\n",
        "k=0\n",
        "k2=0\n",
        "for sent in reviews:\n",
        "  sent_embed = np.empty((maxlen,100))\n",
        "  i=0\n",
        "  for word in sent.split():\n",
        "    if i==maxlen:\n",
        "      break\n",
        "    \n",
        "    try:\n",
        "      sent_embed[i] = np.array(embeddings_dictionary[word]).reshape((1,100))\n",
        "    except KeyError: \n",
        "      sent_embed[i] = np.zeros((1,100))\n",
        "      k+=1\n",
        "    print(sent_embed.shape)\n",
        "    i+=1\n",
        "    k2+=1\n",
        "\n",
        "  if i<maxlen:\n",
        "    padding_matrix = np.zeros((maxlen-i,100))\n",
        "    sent_embed[i:] = padding_matrix\n",
        "  embedding_matrix[j] = sent_embed\n",
        "  j+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmPOI12-ABTJ"
      },
      "source": [
        "X = embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pNug9rLrYnA"
      },
      "source": [
        "y = np.empty((len(reviews),maxlen))\n",
        "com = np.ones((1,maxlen))\n",
        "i=0\n",
        "for label in labels:\n",
        "  y[i] = np.array(label*com)\n",
        "  i+=1\n",
        "y = y.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q6izMs9NCFA"
      },
      "source": [
        "# fp = open('/content/Train-Dev_test split.txt', 'r')\n",
        "sent=np.loadtxt('/content/drive/MyDrive/Train-Dev_test split.txt',delimiter=',',dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coaq_54AJyXH"
      },
      "source": [
        "X_train = np.empty((len(reviews),maxlen,100))\n",
        "X_test = np.empty((len(reviews),maxlen,100)) \n",
        "X_val = np.empty((len(reviews),maxlen,100))\n",
        "y_train = np.empty((len(reviews),maxlen))\n",
        "y_test = np.empty((len(reviews),maxlen))\n",
        "y_val = np.empty((len(reviews),maxlen))\n",
        "i=0\n",
        "j=0\n",
        "b=0"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqxRA0-JM0xe"
      },
      "source": [
        "for k in range(len(reviews)):\n",
        "  if sent[k][1]=='1':\n",
        "    X_train[i] = X[max(11285,int(sent[k][0])-1)]\n",
        "    y_train[i] = y[max(11285,int(sent[k][0])-1)]\n",
        "    i+=1\n",
        "  elif sent[k][1]=='2':\n",
        "    X_val[b] = X[max(11285,int(sent[k][0])-1)]\n",
        "    y_val[b] = y[max(11285,int(sent[k][0])-1)]\n",
        "    b+=1\n",
        "  elif sent[k][1]=='3':\n",
        "    X_test[j] = X[max(11285,int(sent[k][0])-1)]\n",
        "    y_test[j] = y[max(11285,int(sent[k][0])-1)]\n",
        "    j+=1\n",
        "y_train = y_train.astype(int)\n",
        "y_val = y_val.astype(int)\n",
        "y_test = y_test.astype(int)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5pEj6qlmAzH"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WweIVCcvc_4"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxpULyBfmCy-"
      },
      "source": [
        "Multiplication gate for the network, multiply weights with input/H(t-1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3CEJjqdcNkW"
      },
      "source": [
        "class MultiplyGate:\n",
        "    def forward(self,W, x):\n",
        "        return np.dot(W, x)\n",
        "    def backward(self, W, x, dz):\n",
        "        dW = np.asarray(np.dot(np.transpose(np.asmatrix(dz)), np.asmatrix(x)))\n",
        "        dx = np.dot(np.transpose(W), dz)\n",
        "        return dW, dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXmC93y4mNnD"
      },
      "source": [
        "Addition gate for the network, add terms in the forward prop of RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhuxjAvYcc1P"
      },
      "source": [
        "class AddGate:\n",
        "    def forward(self, x1, x2):\n",
        "        return x1 + x2\n",
        "    def backward(self, x1, x2, dz):\n",
        "        dx1 = dz * np.ones_like(x1)\n",
        "        dx2 = dz * np.ones_like(x2)\n",
        "        return dx1, dx2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpj__gU5cf0-"
      },
      "source": [
        "class Sigmoid:\n",
        "    def forward(self, x):\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "    def backward(self, x, top_diff):\n",
        "        output = self.forward(x)\n",
        "        return (1.0 - output) * output * top_diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr0o6mRqciEO"
      },
      "source": [
        "class Tanh:\n",
        "    def forward(self, x):\n",
        "        return np.tanh(x)\n",
        "    def backward(self, x, top_diff):\n",
        "        output = self.forward(x)\n",
        "        return (1.0 - np.square(output)) * top_diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6ZIyVK4cpHn"
      },
      "source": [
        "class Softmax:\n",
        "  def predict(self, x):\n",
        "    log_c = np.max(x, axis=x.ndim - 1, keepdims=True)\n",
        "    y = np.sum(np.exp(x - log_c), axis=x.ndim - 1, keepdims=True)\n",
        "    return np.exp(x - log_c)/y\n",
        "  def loss(self, x, y):\n",
        "    probs = self.predict(x)\n",
        "    return -np.log(probs[y])\n",
        "  def diff(self, x, y):\n",
        "    probs = self.predict(x)\n",
        "    probs[y] -= 1.0\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XJgffZdnnee"
      },
      "source": [
        "1 RNN layer is compiled here, both forward and backward propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x61wxPqeBkf"
      },
      "source": [
        "mulGate = MultiplyGate()\n",
        "addGate = AddGate()\n",
        "activation = Sigmoid()\n",
        "\n",
        "class RNNLayer:\n",
        "    def forward(self, x, prev_s, U, W, V):\n",
        "        self.mulu = mulGate.forward(U, x)\n",
        "        self.mulw = mulGate.forward(W, prev_s)\n",
        "        self.add = addGate.forward(self.mulw, self.mulu)\n",
        "        self.s = activation.forward(self.add)\n",
        "        self.mulv = mulGate.forward(V, self.s)\n",
        "        \n",
        "    def backward(self, x, prev_s, U, W, V, diff_s, dmulv):\n",
        "        self.forward(x, prev_s, U, W, V)\n",
        "        dV, dsv = mulGate.backward(V, self.s, dmulv)\n",
        "        ds = dsv + diff_s\n",
        "        dadd = activation.backward(self.add, ds)\n",
        "        dmulw, dmulu = addGate.backward(self.mulw, self.mulu, dadd)\n",
        "        dW, dprev_s = mulGate.backward(W, prev_s, dmulw)\n",
        "        dU, dx = mulGate.backward(U, x, dmulu)\n",
        "        return (dprev_s, dU, dW, dV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_iL3PIooIeJ"
      },
      "source": [
        "Entire model is compiled here, both forward and backward propagation, contains both gradient clipping and regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWL90b0UdCOh"
      },
      "source": [
        "class Model:\n",
        "    def __init__(self, word_dim, hidden_dim=128, bptt_truncate=4):\n",
        "        self.word_dim = word_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bptt_truncate = bptt_truncate\n",
        "        self.U = np.random.uniform(-np.sqrt(1. / word_dim), np.sqrt(1. / word_dim), (hidden_dim, word_dim))\n",
        "        self.W = np.random.uniform(-np.sqrt(1. / hidden_dim), np.sqrt(1. / hidden_dim), (hidden_dim, hidden_dim))\n",
        "        self.V = np.random.uniform(-np.sqrt(1. / hidden_dim), np.sqrt(1. / hidden_dim), (word_dim, hidden_dim))\n",
        "\n",
        "    def forward_propagation(self, x):\n",
        "        # The total number of time steps\n",
        "        T = len(x)\n",
        "        layers = []\n",
        "        prev_s = np.zeros(self.hidden_dim)\n",
        "        # For each time step...\n",
        "        for t in range(T):\n",
        "            layer = RNNLayer()\n",
        "            input = x[t]\n",
        "            layer.forward(input, prev_s, self.U, self.W, self.V)\n",
        "            prev_s = layer.s\n",
        "            layers.append(layer)\n",
        "        return layers\n",
        "\n",
        "    def predict(self, x):\n",
        "        output = Softmax()\n",
        "        layers = self.forward_propagation(x)\n",
        "        return [np.argmax(output.predict(layer.mulv)) for layer in layers]\n",
        "\n",
        "    def calculate_loss(self, x, y):\n",
        "        assert len(x) == len(y)\n",
        "        output = Softmax()\n",
        "        layers = self.forward_propagation(x)\n",
        "        loss = 0.0\n",
        "        for i, layer in enumerate(layers):\n",
        "            loss += output.loss(layer.mulv, y[i])\n",
        "        return loss / float(len(y))\n",
        "\n",
        "    def calculate_total_loss(self, X, Y):\n",
        "        loss = 0.0\n",
        "        for i in range(len(Y)):\n",
        "            loss += self.calculate_loss(X[i], Y[i])\n",
        "        return loss / float(len(Y))\n",
        "\n",
        "    def bptt(self, x, y):    #back propagation through time\n",
        "        assert len(x) == len(y)\n",
        "        output = Softmax()\n",
        "        layers = self.forward_propagation(x)\n",
        "        dU = np.zeros(self.U.shape)\n",
        "        dV = np.zeros(self.V.shape)\n",
        "        dW = np.zeros(self.W.shape)\n",
        "\n",
        "        T = len(layers)\n",
        "        prev_s_t = np.zeros(self.hidden_dim)\n",
        "        diff_s = np.zeros(self.hidden_dim)\n",
        "        for t in range(0, T):\n",
        "            dmulv = output.diff(layers[t].mulv, y[t])\n",
        "            input = x[t]\n",
        "            dprev_s, dU_t, dW_t, dV_t = layers[t].backward(input, prev_s_t, self.U, self.W, self.V, diff_s, dmulv)\n",
        "            prev_s_t = layers[t].s\n",
        "            dmulv = np.zeros(self.word_dim)\n",
        "            #gradient clipping is done here, \n",
        "            for i in range(t-1, max(-1, t-self.bptt_truncate-1), -1):\n",
        "                input = np.zeros(self.word_dim)\n",
        "                input = x[i]\n",
        "                prev_s_i = np.zeros(self.hidden_dim) if i == 0 else layers[i-1].s\n",
        "                dprev_s, dU_i, dW_i, dV_i = layers[i].backward(input, prev_s_i, self.U, self.W, self.V, dprev_s, dmulv)\n",
        "                dU_t += dU_i\n",
        "                dW_t += dW_i\n",
        "            dV += dV_t\n",
        "            dU += dU_t\n",
        "            dW += dW_t\n",
        "        return (dU, dW, dV)\n",
        "\n",
        "    def sgd_step(self, x, y, reg_param, learning_rate):   # Regularization is implemented here, reg_param is the regularization parameter\n",
        "        dU, dW, dV = self.bptt(x, y)\n",
        "        self.U -= learning_rate * dU + (reg_param/maxlen)*self.U\n",
        "        self.V -= learning_rate * dV + (reg_param/maxlen)*self.V\n",
        "        self.W -= learning_rate * dW + (reg_param/maxlen)*self.W\n",
        "\n",
        "    def train(self, X, Y, learning_rate, reg_param, nepoch=100, evaluate_loss_after=5):\n",
        "        num_examples_seen = 0\n",
        "        #initialize the vector\n",
        "        m_t = np.zeros(3) \n",
        "        v_t = np.zeros(3)\n",
        "        t = np.zeros(3)\n",
        "        losses = []\n",
        "        for epoch in range(nepoch):\n",
        "            if (epoch % evaluate_loss_after == 0):\n",
        "                loss = self.calculate_total_loss(X, Y)\n",
        "                losses.append((num_examples_seen, loss))\n",
        "                time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                print(\"%s: Loss after num_examples_seen=%d epoch=%d: %f\" % (time, num_examples_seen, epoch, loss))\n",
        "                # Adjust the learning rate if loss increases\n",
        "                if len(losses) > 1 and losses[-1][1] > losses[-2][1]:\n",
        "                    learning_rate = learning_rate * 0.5\n",
        "                    print(\"Setting learning rate to %f\" % learning_rate)\n",
        "                sys.stdout.flush()\n",
        "            # For each training example...\n",
        "            for i in range(len(Y)):\n",
        "                self.sgd_step(X[i], Y[i], reg_param, learning_rate)\n",
        "                num_examples_seen += 1\n",
        "        return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzjnhhUdoWor"
      },
      "source": [
        "Code for training, trained in batches of 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN94zuES4tow"
      },
      "source": [
        "loss = []\n",
        "word_dim = 100 # length of embedding of glove vector\n",
        "hidden_dim = 128 # size of hidden dimensions\n",
        "num_classes = 5  # number of classes\n",
        "\n",
        "np.random.seed(10)\n",
        "rnn = Model(word_dim, num_classes, hidden_dim)\n",
        "for i in range(112):\n",
        "  losses = rnn.train(X_train[i*100:100*(i+1)], y_train[i*100:100*(i+1)], reg_param = 0.02, learning_rate=0.0001, nepoch=2, evaluate_loss_after=1)\n",
        "  loss.append(losses[-1][1])\n",
        "  print(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwGh2JYmTfDM"
      },
      "source": [
        "#hyperparameter testing\n",
        "# hidden size of RNN, alpha, epoch\n",
        "#word embeddings are not considered as hyperparameter as pretrained glove matrix are hard to handle on colab(only size 100 used)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3AOb2-bTe5Y"
      },
      "source": [
        "hidden_vals = [64,128,256]\n",
        "alpha_vals = [0.1,0.01,0.001]\n",
        "reg_param_vals = [0, 0.02, 0.04, 0.08, 0.16, 0.32]\n",
        "hidden_param = []\n",
        "reg_param = []\n",
        "learning_rate = []\n",
        "word_dim = 100\n",
        "num_classes = 5\n",
        "\n",
        "for hidden_dim in hidden_vals:   # hidden dimensions\n",
        "  np.random.seed(10)\n",
        "  rnn = Model(word_dim, num_classes, hidden_dim)\n",
        "  losses = rnn.train(X_val, y_val, reg_param = 0.02, learning_rate=0.005, nepoch=10, evaluate_loss_after=1)\n",
        "  hidden_param.append(losses[-1][1])\n",
        "  print(losses)\n",
        "\n",
        "for lr in alpha_vals:              # learning rate\n",
        "  np.random.seed(10)\n",
        "  rnn = Model(word_dim, num_classes, hidden_dim)\n",
        "  losses = rnn.train(X_val, y_val, reg_param = 0.02, learning_rate=lr, nepoch=10, evaluate_loss_after=1)\n",
        "  learning_rate.append(losses[-1][1])\n",
        "  print(losses)\n",
        "\n",
        "for lamb in reg_param_vals:        # regularization parameter, both with regularization and without one\n",
        "  np.random.seed(10)\n",
        "  rnn = Model(word_dim, num_classes, hidden_dim)\n",
        "  losses = rnn.train(X_val, y_val, reg_param = lamb, learning_rate=0.005, nepoch=10, evaluate_loss_after=1)\n",
        "  reg_param.append(losses[-1][1])\n",
        "  print(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGv_rdvWVZeS"
      },
      "source": [
        "Printing values of various hyperparameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkbnUIt1bkx8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('hidden parameter')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('number of nodes')\n",
        "plt.plot([64,128,256], hidden_param)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKZpKRLNcnD3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('regularization parameter, zero corresponds to no regularization')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('value of lambda')\n",
        "plt.plot([0, 0.02, 0.04, 0.08, 0.16, 0.32], reg_param)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Rfoy69diip"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('learning rate')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('value of alpha')\n",
        "plt.plot([0.1,0.01,0.001], learning_rate)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phKSeIHDlseD"
      },
      "source": [
        "Code testing , do not run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIe8mzJUkUu1"
      },
      "source": [
        "said = [-0.13569,0.14029,0.0041988,-0.32062,0.012745,0.92511,-0.44523,-0.16454,0.6016,0.4267,0.26053,0.71426,0.57701,-0.09754,0.64286,-0.0002438,-0.3013,0.097057,-0.21678,-0.27131,0.30927,3.0062,-0.3179,0.28998,-0.39905,0.11234,0.19019,-0.49873,0.11857,-0.22241,-0.52668,-0.040781,-0.16783,-0.35887,0.60394,-0.069027,-0.60611,-0.22444,-0.51665,0.77766,-0.41533,-0.23924,-0.64725,0.16413,-0.41185,-0.15507,0.52085,-0.29298,0.034067,-0.71414,0.17124,0.18186,-0.62824,-0.21882,-0.3784,-0.60484,-0.10613,-0.0065723,0.52873,-0.12537,1.1519,0.16512,-0.12301,0.73452,0.15381,-0.021303,-0.4185,0.32132,-0.56697,0.58886,-0.19564,-0.1671,0.35969,0.42898,-0.071104,0.50165,0.15248,-0.089535,-0.67192,0.1817,-0.030661,-0.20289,-0.23925,0.33899,0.088455,-0.16614,-0.78902,0.14403,-0.22256,-1.377,0.38399,-0.14929,-0.16867,-0.73194,-0.76784,0.96968,0.26804,0.36036,-0.33896,-0.17303,0.3866,-0.76154,-0.52335,0.091027,0.049086,0.059747,0.13165,1.9048,-0.77324,-0.094455,0.17805,-0.096256,0.0684,-0.36729,0.011347,0.12147,0.2453,-0.4354,-0.1733,0.36181,0.78902,0.66458,0.45523,0.079105,0.30238,-0.29991,-0.25161,-0.060112,0.59835,-5.4345e-06,0.47396,-0.25035,-0.16549,0.54022,0.62029,0.43227,0.44656,-0.45033,-0.22726,-0.060223,0.42781,0.34668,-0.38491,-0.25167,1.0969,0.66604,0.036542,-0.32485,0.4289,0.13762,-0.22326,0.69871,0.23841,0.89013,0.23899,-0.51714,-0.050005,0.1487,0.055402,-0.41163,-0.33454,-0.014032,0.36476,-0.23411,-0.13272,-0.050314,0.19593,0.16193,0.28734,0.13478,0.74715,-0.060806,0.14221,0.047109,-0.44866,-0.408,-0.68475,-0.25236,0.16233,-0.33454,0.69021,-0.36958,-0.4338,-0.099908,-0.53847,-0.16861,-0.54684,0.40052,0.11458,0.45688,0.28415,0.43329,0.11012,0.22958,0.024016,0.20695,0.23759,0.0087948,-0.13017,-0.25626]\n",
        "were = [-0.29716,-0.025477,-0.43389,-0.52616,-0.14354,0.33104,-0.77455,-0.096218,0.15055,0.40654,0.47132,-0.043477,0.018865,-0.31835,0.0021327,0.51416,0.07266,0.86377,0.39094,-0.2941,0.022928,2.9991,-0.14775,-0.48026,-0.46537,-0.28892,-0.28702,-0.78647,0.21987,0.23957,0.2389,0.04237,0.05836,0.11709,-0.18796,-0.31004,-0.64738,-0.7185,0.33694,0.3713,0.6525,-0.48662,0.093115,0.068172,-0.064165,0.0067802,0.8213,-0.46428,0.052333,-0.054842,-0.81224,0.12655,-0.1431,0.53736,-0.10751,-0.1201,-0.13545,0.20551,-0.25494,-0.14893,0.090701,0.36655,-0.20965,0.673,0.51765,-0.35084,-0.47291,0.31541,-0.19238,-0.02999,0.018858,-0.40037,0.0066421,0.12526,0.097123,-0.10354,0.027577,0.073137,0.22532,-0.41189,0.047902,0.11876,-0.57981,0.54385,0.33422,0.3453,0.2162,-0.69258,-0.13744,-0.59278,-0.054606,-0.10773,0.79549,-0.025879,-0.116,0.4545,0.070413,-0.49586,-0.35715,-0.28674,0.5773,-0.81279,0.019403,0.091408,0.13133,0.34139,0.52689,0.64284,-0.26375,-0.018898,-0.51385,-0.062924,0.16246,0.48888,0.72696,0.49494,-0.45197,-0.25742,0.0047182,-0.91796,0.46416,0.1966,0.67564,-0.080587,0.12588,-1.2989,-0.02176,0.4114,0.41177,-0.60598,0.10907,0.0048411,0.36911,-0.35354,0.50438,0.43354,-0.60223,-0.070002,-0.59426,0.081687,-0.74034,-0.071562,-0.14978,-0.47965,1.3329,0.52734,-0.14646,-0.18742,0.23384,-0.088226,-0.22079,0.42821,0.07259,-0.86941,0.065263,0.14209,-0.38875,0.62475,-0.043056,-0.1405,-0.087399,0.26025,0.18315,0.57811,-0.3948,0.84753,0.25191,0.15239,-0.86611,0.56031,-0.13038,0.31795,0.089552,0.24,0.11417,0.13804,-0.47975,-0.49307,-0.65965,-0.03232,0.99141,0.49788,-0.43471,-0.082005,-0.22052,-0.069465,-0.025023,0.40196,-0.22087,0.1288,-0.11603,0.21029,-0.37609,-0.065688,0.72272,0.11403,-0.08957,-0.34873,-0.47252,0.85348]\n",
        "noti = [0.34303,0.4082,-0.023317,-0.36093,0.0526,0.28925,-0.72928,0.077745,0.25907,0.20004,0.14167,0.49461,-0.043323,-0.17258,0.071147,0.26755,-0.17498,0.81793,0.16388,-0.43131,-0.10978,3.3862,-0.39972,0.079416,0.00044842,0.025372,-0.066779,-0.073348,0.11878,-0.071623,-0.095796,-0.11912,0.13945,0.081686,0.11199,-0.379,-0.86427,-0.65059,0.0072629,0.11515,0.13784,-0.37365,-0.023701,0.31684,-0.22221,0.0094901,0.48885,-0.23512,0.20877,-0.36594,-0.086444,-0.19801,-0.43175,0.22803,0.32309,-0.20011,0.1592,-0.27653,-0.043781,0.30648,0.21574,0.26831,-0.12455,-0.11471,0.29235,-0.041827,-0.27627,0.6043,0.1427,0.5277,0.87699,0.22292,-0.13668,0.13928,-0.46867,-0.13543,-0.47535,-0.46317,0.01747,-0.231,0.14377,-0.15767,0.26873,0.24767,0.24199,-0.12111,-0.40109,-0.5547,0.025637,-1.227,0.25114,0.35073,0.62196,-0.19648,-0.27999,0.09606,-0.082684,-0.014249,-0.099184,-0.11603,0.35344,-0.033989,-0.060309,-0.48616,0.14479,-0.17586,-0.36172,1.2432,-0.4364,-0.16122,-0.13308,-0.34845,0.21167,0.097091,0.23652,0.027138,0.29117,-0.36449,-0.38529,-0.17665,0.37197,0.14412,0.40894,-0.11261,0.097247,-0.24356,-0.018665,0.16607,0.3411,-0.28714,-0.28679,0.49481,0.40374,-0.39017,0.35375,0.12035,-0.065398,-0.16071,-0.044542,-0.28337,0.042688,0.027212,0.37139,-0.30543,1.4214,0.53121,-0.46548,-0.19737,-0.0054895,-0.18203,0.11912,0.42438,-0.40208,0.058662,0.10283,-0.30155,-0.33827,0.34796,-0.082353,0.51862,-0.29775,0.14422,0.44026,-0.123,-0.23571,0.17797,0.11558,0.18801,-0.30945,0.48821,0.1476,0.40829,0.19013,-0.13821,0.333,0.011581,-0.57089,0.30526,0.20618,0.17889,1.2769,-0.11154,-0.47002,-0.12611,-0.20999,-0.013965,-0.078315,0.15576,0.099716,0.27449,-0.36542,0.24097,0.11508,-0.032185,0.18049,-0.028734,0.13449,0.1724,0.031143,0.031783]\n",
        "this = [0.39086,0.65528,0.064706,-0.33366,0.18502,-0.027321,-0.3878,-0.15081,0.39917,-0.30206,0.23819,0.45941,-0.023606,-0.043237,0.54309,-0.085014,-0.044168,0.66163,-0.39539,-0.27537,0.37465,3.0274,-0.085225,0.1731,0.58574,-0.36105,0.18828,0.41495,0.13081,-0.039031,-0.24917,-0.16286,0.012653,-0.0098054,-0.11815,-0.16429,-0.90413,-0.57109,0.026838,-0.43601,-0.15484,-0.37619,0.24899,0.51744,0.0009744,0.12833,0.24256,0.26005,0.050365,-0.016651,0.091362,-0.31346,-0.0078254,0.72088,0.1415,-0.0050633,-0.24204,-0.39191,-0.058966,-0.053058,0.25604,0.074284,-0.23051,-0.54815,-0.22384,-0.031049,0.019959,0.17193,-0.054222,0.033631,0.39632,0.24702,-0.14935,0.42653,-0.27151,0.28648,-0.46361,-0.21448,-0.46598,0.057568,-0.12724,-0.14651,-0.36591,0.34369,0.05271,-0.018639,-0.46642,-0.49551,0.62577,-0.64458,0.41497,0.15695,0.5569,0.074682,-0.59488,0.15163,0.0050693,-0.11666,0.010334,-0.21172,-0.19726,0.25814,0.16371,0.10557,-0.0063813,0.12384,-0.23964,0.99755,-0.78864,0.25616,0.28623,-0.45224,-0.0022179,0.057452,0.041398,0.09977,0.027042,-0.088172,-0.29811,-0.026336,0.069132,0.23899,0.35541,-0.063479,0.0059764,-0.21982,0.38767,0.1966,-0.027814,-0.088787,-0.19875,0.14134,0.22949,-0.27561,0.13077,0.41609,-0.10151,-0.077741,-0.16479,0.043119,-0.24528,0.21869,0.095889,-0.32395,1.5937,0.31002,-0.058686,-0.45488,0.077925,0.17054,0.0018438,0.71656,-0.42026,0.07127,0.51768,-0.21712,-0.2484,0.22494,0.069718,-0.38438,0.19313,-0.1105,-0.10447,-0.32604,-0.26355,0.073983,-0.27133,0.084472,-0.58727,0.53549,-0.059486,0.22041,0.64939,-0.11922,-0.0081812,-0.063136,-0.15009,-0.096871,-0.27551,0.23581,1.8095,-0.35952,-0.026458,0.47649,-0.18462,0.057494,-0.11701,0.23265,0.043931,0.32839,0.084436,0.051592,0.021732,0.10135,0.075084,-0.23,-0.20108,0.3865,0.052221,-0.22646]\n",
        "who = [0.075467,-0.29236,-0.26037,-0.28167,0.16097,-0.19472,-0.28206,0.49141,-0.0041119,0.095879,0.33396,0.016874,0.20616,-0.15743,-0.16138,0.21538,-0.14836,0.02546,-0.43681,-0.063661,0.55261,3.0819,-0.11784,-0.46131,-0.27609,0.20948,-0.20544,-0.57155,0.33448,0.15913,0.0025436,0.18004,0.13472,-0.097404,0.35537,-0.47428,-0.79257,-0.54418,0.0243,0.63599,0.12337,-0.12913,-0.26565,-0.24957,-0.52199,-0.40523,0.48403,0.018373,0.23039,0.062138,-0.19292,0.29506,-0.35793,0.16702,0.31868,-0.36054,-0.10978,-0.15632,0.45921,0.096475,-0.377,-0.077615,-0.48899,0.20575,0.50543,0.053419,-0.25978,0.51042,0.097521,0.32606,0.14354,0.0022715,0.48615,0.46938,-0.41124,-0.17148,-0.39744,-0.28901,-0.17756,0.037001,0.3483,0.15934,-0.74281,0.18897,0.043685,0.57208,-0.67016,-0.043947,-0.28336,-0.31996,-0.20404,-0.087898,-0.15724,0.021818,-0.56757,0.63296,-0.10097,-0.065576,0.0058269,0.033035,0.39783,-0.31166,-0.61089,0.27559,0.10008,-0.4199,0.006356,1.8717,0.31473,-0.36004,0.81384,-0.2171,-0.018459,-0.22632,0.14585,-0.1435,-0.041424,0.55974,-0.66752,-0.21959,0.19011,0.33015,0.6129,0.46771,0.42026,-0.52819,0.023165,0.03291,0.47306,0.014006,-0.17396,-0.44362,0.41377,-0.20679,0.39283,0.30211,0.073134,0.042164,-0.9271,-0.47614,0.2431,-0.13379,-0.22238,-0.041457,1.585,0.37481,0.025994,-0.24272,0.30578,0.14687,0.11666,-0.029418,-0.078339,-0.22512,0.13315,-0.064842,-0.28687,-0.01056,-0.34668,0.042145,-0.60041,0.82481,0.31022,0.16489,-0.072921,0.19394,-0.098498,-0.020383,-0.40909,-0.10404,0.19169,-0.15969,0.38026,0.62802,0.2595,-0.33367,-0.73333,-0.40743,0.68423,-0.066338,0.50436,-0.28983,-0.39086,-0.045931,-0.26624,-0.1677,-0.15037,0.14828,-0.28143,-0.17087,-0.25576,-0.056283,-0.1665,0.35106,0.041032,0.27311,0.03002,0.16465,-0.084189,0.057506]\n",
        "they = [0.0528,0.13495,-0.38214,-0.27999,-0.38392,-0.084598,-0.37277,0.10046,-0.023454,0.71256,0.024259,0.2814,0.010209,-0.19417,-0.30018,0.2074,-0.18105,0.71611,-0.11311,-0.26412,0.17681,3.2366,-0.2329,-0.07999,0.13482,-0.22448,-0.11799,-0.092002,0.23552,-0.12608,0.12557,-0.21536,0.12587,0.049804,0.024991,-0.55934,-0.93924,-0.51797,0.42125,0.34652,0.19897,-0.014204,0.17652,0.43155,-0.38901,0.032722,0.95275,-0.24641,0.12699,0.24171,-0.2495,0.13663,-0.58702,0.53192,0.25364,-0.44631,0.071339,-0.1072,0.016232,0.28356,0.25355,0.36077,-0.066849,0.22595,0.26663,0.1958,-0.21102,0.39934,-0.0066386,0.095334,0.46205,0.028948,0.20202,0.1217,-0.1758,-0.24526,-0.29105,0.153,-0.081641,-0.1527,-0.061132,0.33011,-0.27052,0.24315,0.31077,0.24527,-0.55383,-0.56974,-0.055326,-1.1106,0.23658,0.092638,0.73168,0.085777,-0.24735,0.2301,0.049224,-0.10027,-0.12215,-0.32324,0.45269,-0.2575,-0.16278,-0.18948,0.23016,0.33619,0.11044,1.0879,-0.48341,-0.24421,-0.11329,-0.028835,0.19768,0.31868,0.14758,0.1623,0.071596,0.032118,0.072414,-0.16726,0.74261,0.12729,0.3097,-0.32765,0.12688,-0.69808,0.20057,0.2493,0.49528,-0.4856,-0.46447,0.41582,0.47338,-0.38178,0.4538,0.18398,-0.12377,-0.28023,-0.22348,-0.11058,-0.26895,-0.13358,0.21927,-0.46339,1.4292,0.67536,-0.17342,-0.46714,0.0090229,0.099559,0.15438,0.44203,-0.49867,-0.061944,-0.0033505,-0.17547,-0.1701,0.34289,-0.093336,0.28919,-0.32519,0.13184,0.0011452,-0.084836,-0.26536,0.46792,0.23974,0.044068,-0.75486,0.30871,0.10976,0.039385,0.48202,0.053616,0.43554,0.057253,-0.56428,-0.33534,-0.032656,0.19587,1.2662,-0.3715,-0.74673,-0.19089,-0.2307,0.094298,-0.018306,0.055102,-0.028414,0.27891,-0.22275,0.25638,0.064459,0.031974,0.19601,0.004318,0.043765,0.42737,-0.20698,0.44511]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB1hClQpXFfI",
        "outputId": "faff3d1f-6875-45e1-ccc2-252738d587de"
      },
      "source": [
        "print(reviews[0].split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', 's', 'new', 'conan', 'and', 'that', 'he', 's', 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', 'jeanclaud', 'van', 'damme', 'or', 'steven', 'segal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S0O-gUOWoHz"
      },
      "source": [
        "a = embeddings_dictionary['movie']\n",
        "b = embeddings_dictionary['was']\n",
        "c = embeddings_dictionary['awesome']\n",
        "d = embeddings_dictionary['it']\n",
        "e = embeddings_dictionary['was']\n",
        "f = embeddings_dictionary['horrible']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiHw59NKrnUd",
        "outputId": "65475906-d648-4f71-cc99-b8b52158a22d"
      },
      "source": [
        "print(\"said = [\"+said.replace(\" \",\",\")+']')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "said = [-0.13569,0.14029,0.0041988,-0.32062,0.012745,0.92511,-0.44523,-0.16454,0.6016,0.4267,0.26053,0.71426,0.57701,-0.09754,0.64286,-0.0002438,-0.3013,0.097057,-0.21678,-0.27131,0.30927,3.0062,-0.3179,0.28998,-0.39905,0.11234,0.19019,-0.49873,0.11857,-0.22241,-0.52668,-0.040781,-0.16783,-0.35887,0.60394,-0.069027,-0.60611,-0.22444,-0.51665,0.77766,-0.41533,-0.23924,-0.64725,0.16413,-0.41185,-0.15507,0.52085,-0.29298,0.034067,-0.71414,0.17124,0.18186,-0.62824,-0.21882,-0.3784,-0.60484,-0.10613,-0.0065723,0.52873,-0.12537,1.1519,0.16512,-0.12301,0.73452,0.15381,-0.021303,-0.4185,0.32132,-0.56697,0.58886,-0.19564,-0.1671,0.35969,0.42898,-0.071104,0.50165,0.15248,-0.089535,-0.67192,0.1817,-0.030661,-0.20289,-0.23925,0.33899,0.088455,-0.16614,-0.78902,0.14403,-0.22256,-1.377,0.38399,-0.14929,-0.16867,-0.73194,-0.76784,0.96968,0.26804,0.36036,-0.33896,-0.17303,0.3866,-0.76154,-0.52335,0.091027,0.049086,0.059747,0.13165,1.9048,-0.77324,-0.094455,0.17805,-0.096256,0.0684,-0.36729,0.011347,0.12147,0.2453,-0.4354,-0.1733,0.36181,0.78902,0.66458,0.45523,0.079105,0.30238,-0.29991,-0.25161,-0.060112,0.59835,-5.4345e-06,0.47396,-0.25035,-0.16549,0.54022,0.62029,0.43227,0.44656,-0.45033,-0.22726,-0.060223,0.42781,0.34668,-0.38491,-0.25167,1.0969,0.66604,0.036542,-0.32485,0.4289,0.13762,-0.22326,0.69871,0.23841,0.89013,0.23899,-0.51714,-0.050005,0.1487,0.055402,-0.41163,-0.33454,-0.014032,0.36476,-0.23411,-0.13272,-0.050314,0.19593,0.16193,0.28734,0.13478,0.74715,-0.060806,0.14221,0.047109,-0.44866,-0.408,-0.68475,-0.25236,0.16233,-0.33454,0.69021,-0.36958,-0.4338,-0.099908,-0.53847,-0.16861,-0.54684,0.40052,0.11458,0.45688,0.28415,0.43329,0.11012,0.22958,0.024016,0.20695,0.23759,0.0087948,-0.13017,-0.25626]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8auTKdB_oCL",
        "outputId": "c7dd1b23-1560-4ae9-9147-07b11c450629"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhbPHjGjmTV"
      },
      "source": [
        "X_train = np.array([[a,b,c],[d,e,f]])\n",
        "y_train = np.array([[4,4,4],[0,0,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr4Jkfzi0Und"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import savetxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MizUeFH06GHX",
        "outputId": "d9235669-886e-4447-cd68-6cf4475fa4ac"
      },
      "source": [
        "#fetch dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "pat='/content/drive/My Drive/Projects/STCS assignment(Word vectors)/'\n",
        "pat2='/content/drive/My Drive/Projects/HASOC/'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYC74Z-Q_5aq"
      },
      "source": [
        "a=np.loadtxt(pat+'Movie Review Dataset.txt',delimiter='\\t',dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qqlIrYwLPGC"
      },
      "source": [
        "a2=[]\n",
        "for e1,e2 in a:\n",
        "    a2+=[e2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoZtV7Y-LsUO",
        "outputId": "1ff91d46-7354-41be-fa60-00ae8b6f6bc7"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['phrase ids|sentiment values', '0|0.5', '1|0.5', ...,\n",
              "       '239229|0.33333', '239230|0.88889', '239231|0.5'], dtype='<U27')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKVTWGkXLwNE"
      },
      "source": [
        "d=np.loadtxt(pat+'Dictionary.txt',delimiter='\\t',dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ-mg5BcL3rC",
        "outputId": "f4348269-6351-413d-e6a3-0a9d70d008f3"
      },
      "source": [
        "len(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "239225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bec_pW8zL65e"
      },
      "source": [
        "d2=' '.join(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76G-1abtNpUY"
      },
      "source": [
        "d3=d2.split('|')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXB5zYuHN7p7",
        "outputId": "eea52f7e-3d61-4ef7-b543-1bcbf3a151ef"
      },
      "source": [
        "len(d3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "239184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YGc42HAN9e-"
      },
      "source": [
        "d3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZQbQ-HxEOpYn",
        "outputId": "8c5118fc-b047-4699-e6e7-6ea65956befb"
      },
      "source": [
        "d3[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'220444'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBowC0joOABN"
      },
      "source": [
        "p1=[d3[0]]\n",
        "p2=[]\n",
        "for el in d3[1:]:\n",
        "  e=el.split(' ')\n",
        "  p1+=[' '.join(e[1:])]\n",
        "  p2+=[int(e[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08uDM05aPhOL",
        "outputId": "b02ab5ae-67f3-4e3b-8bab-5967c1a36265"
      },
      "source": [
        "len(p1),len(p2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(239184, 239183)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_igS-psAPrYs",
        "outputId": "6f13dcce-553a-4e6a-d25d-b2b8b0918b5a"
      },
      "source": [
        "p1[-2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'É um passatempo descompromissado'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W415-rNLP0gW"
      },
      "source": [
        "p1=p1[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thioW6U8jAiV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65gP0pDKZkCY",
        "outputId": "edce7442-fe65-4a4b-8264-a7b678d07b90"
      },
      "source": [
        "p2[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHxjEczCQuRA"
      },
      "source": [
        "dicti=dict(zip(p2,p1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "npabPXduZhM7",
        "outputId": "d2e554b9-3fca-4a79-a24b-368db060723b"
      },
      "source": [
        "dicti[220444]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'É um passatempo descompromissado'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9m-J-uZdRBJ"
      },
      "source": [
        "p3=[]\n",
        "for el in a2:\n",
        "  try:\n",
        "    p3+=[p2[p1.index(el)]]\n",
        "  except ValueError:\n",
        "    p3+=[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2bAEtU5lJfm"
      },
      "source": [
        "p4=np.array(p3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnzF6WAPlJqt",
        "outputId": "8f5d3357-5e63-457d-dac5-b3b6bf69d67b"
      },
      "source": [
        "len(p4[p4!=-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11285"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdAtbRkbLVAf"
      },
      "source": [
        "sent=np.loadtxt(pat+'Senti_scores.txt',delimiter='|',dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D1o8IEroSCB",
        "outputId": "4a280973-0226-4aa7-f147-6ea863988a4e"
      },
      "source": [
        "sent[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '0.5'], dtype='<U16')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw16lyxqpLyS"
      },
      "source": [
        "s1=[]\n",
        "s2=[]\n",
        "for e1,e2 in sent[1:]:\n",
        "    s1+=[int(e1)]\n",
        "    s2+=[float(e2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVtbUM_Bpcnq"
      },
      "source": [
        "p6=[]\n",
        "for el in p3:\n",
        "  try:\n",
        "    p6+=[s2[s1.index(el)]]\n",
        "  except ValueError:\n",
        "    p6+=[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTD971UNp0TO",
        "outputId": "d7bfc21f-c09d-4c31-eb12-d11730044d5a"
      },
      "source": [
        "p6[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51389"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7nWMyzbsALc"
      },
      "source": [
        "#p6 all senti scores in order of sentence if not present has -1\n",
        "#p3 phrase index of all sentence in that order\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}