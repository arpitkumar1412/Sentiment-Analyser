{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngis1Nw0_Da9"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ658h0Hlyr0"
      },
      "source": [
        "Data preprocessing, converting to numpy array and dividing into train, test, validation dataset. Data location of both glove matrix, sentiment(2), movie.txt and data3.csv(CBOW matrix have to be changed) has to be changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR-lI_EvB7uh",
        "outputId": "b5c9784b-0e10-4000-cfdf-52e208b7333e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IVUnMIkxY-L"
      },
      "source": [
        "pat='/content/drive/My Drive/Projects/STCS assignment(Word vectors)/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQThwALe-TCW"
      },
      "source": [
        "#sentiment score\n",
        "df = pd.read_csv (pat+'sentiment (2).csv')\n",
        "print (df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV01z2XJ_LDH"
      },
      "source": [
        "reviews = df['review']\n",
        "labels = np.array(df['senti_score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U_heEDS_KXl"
      },
      "source": [
        "#assigning label\n",
        "for label in range(len(labels)):\n",
        "  if float(labels[label])<=0.2:\n",
        "    labels[label] = 0\n",
        "  elif float(labels[label])<=0.4:\n",
        "    labels[label] = 1\n",
        "  elif float(labels[label])<=0.6:\n",
        "    labels[label] = 2\n",
        "  elif float(labels[label])<=0.8:\n",
        "    labels[label] = 3\n",
        "  elif float(labels[label])<=1.0:\n",
        "    labels[label] = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySslpYGA-SDo"
      },
      "source": [
        "reviews = reviews.str.lower()\n",
        "for i in range(df.shape[0]):\n",
        "  reviews[i] = re.sub(r'[^\\w\\s]', '', reviews[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BJDkQ7dyM5Y"
      },
      "source": [
        "a=np.loadtxt(pat+'Movie Review Dataset.txt',delimiter='\\t',dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXlfqSVti104"
      },
      "source": [
        "a2=[]\n",
        "for e1,e2 in a:\n",
        "    a2+=[e2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGdQyVrakj5B",
        "outputId": "6667a88d-0c3f-4c3e-b9d0-06d76c72eb2f"
      },
      "source": [
        "len(a2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIOlBtaB0oeB",
        "outputId": "b2d0d055-1c24-4252-c0b0-2183fdb052ca"
      },
      "source": [
        "#generating vocabulary\n",
        "q2=[] #contains word of sentences\n",
        "q3=[] #contains sentences\n",
        "for e in a2:\n",
        "  f=[]\n",
        "  for el2 in e.split(' '):\n",
        "    f+=[el2.lower()]\n",
        "    \n",
        "  q2+=f\n",
        "  q3+=[f]\n",
        "sen_len=np.array(q2) \n",
        "n=len(np.unique(sen_len))#Vocabulary size\n",
        "n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgOb-ULC0tIh"
      },
      "source": [
        "qwe=np.unique(sen_len)#list of unique words\n",
        "tab=np.zeros([n,n],dtype=np.int32)#coocurrence matrix\n",
        "word_to_num=dict(zip(qwe,range(n)))#dictionary for word to num\n",
        "sen=np.array(q3)\n",
        "data_training = sen[1:]#remove heading"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPkAuG0Nx2k-",
        "outputId": "81d58dbf-cfbf-4ec7-86bd-9a9967987af5"
      },
      "source": [
        "#loading CBOW vector\n",
        "wemb=np.loadtxt(pat+'data3.csv',delimiter=',')\n",
        "wemb.T.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19538, 400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byCZt9CAyRn4",
        "outputId": "9d4ff107-0219-438e-b357-f71827881dd9"
      },
      "source": [
        "len(qwe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkWiEvazyYzi"
      },
      "source": [
        "#creating a word to vector dictionary\n",
        "embeddings_dictionary=dict(zip(qwe,wemb.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuZ3OYxfd6nG"
      },
      "source": [
        "maxlen = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijmkjH2jAifK"
      },
      "source": [
        "#creating converting entences to embeddings\n",
        "embedding_matrix = np.empty((len(reviews),maxlen,100))\n",
        "j=0\n",
        "k=0\n",
        "k2=0\n",
        "for sent in reviews:\n",
        "  sent_embed = np.empty((maxlen,100))\n",
        "  i=0\n",
        "  for word in sent.split():\n",
        "    if i==maxlen:\n",
        "      break\n",
        "    \n",
        "    try:\n",
        "      sent_embed[i] = np.array(embeddings_dictionary[word]).reshape((1,100))\n",
        "    except KeyError: \n",
        "      sent_embed[i] = np.zeros((1,100))\n",
        "      k+=1\n",
        "    print(sent_embed.shape)\n",
        "    i+=1\n",
        "    k2+=1\n",
        "\n",
        "  if i<maxlen:\n",
        "    padding_matrix = np.zeros((maxlen-i,100))\n",
        "    sent_embed[i:] = padding_matrix\n",
        "  embedding_matrix[j] = sent_embed\n",
        "  j+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmPOI12-ABTJ"
      },
      "source": [
        "X = embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pNug9rLrYnA"
      },
      "source": [
        "#assigning label to y\n",
        "y = np.empty((len(reviews),maxlen))\n",
        "com = np.ones((1,maxlen))\n",
        "i=0\n",
        "for label in labels:\n",
        "  y[i] = np.array(label*com)\n",
        "  i+=1\n",
        "y = y.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZH-yfISLrFx"
      },
      "source": [
        "#Taking only first index(code from RNN)\n",
        "Y=y[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q6izMs9NCFA"
      },
      "source": [
        "#loading data split\n",
        "sent=np.loadtxt(pat+'Train-Dev_test split.txt',delimiter=',',dtype=str,skiprows=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkvCnJOS0bpB",
        "outputId": "63832e88-8878-4023-c797-3f82e0e43c06"
      },
      "source": [
        "sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['1', '1'],\n",
              "       ['2', '1'],\n",
              "       ['3', '2'],\n",
              "       ...,\n",
              "       ['11853', '1'],\n",
              "       ['11854', '1'],\n",
              "       ['11855', '1']], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coaq_54AJyXH"
      },
      "source": [
        "#splitting data\n",
        "X_train = np.empty((7980,maxlen,100))\n",
        "X_test = np.empty((1101,maxlen,100)) \n",
        "X_val = np.empty((2205,maxlen,100))\n",
        "y_train = np.empty((7980))\n",
        "y_test = np.empty((1101))\n",
        "y_val = np.empty((2205))\n",
        "i=0\n",
        "j=0\n",
        "k=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqxRA0-JM0xe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6edb1515-a9dd-4628-9fa4-0a143104bdee"
      },
      "source": [
        "#splitting data\n",
        "b=0\n",
        "for k in range(len(reviews)):\n",
        "  if sent[k][1]=='1':\n",
        "    X_train[i] = X[min(11285,int(sent[k][0])-1)]\n",
        "    y_train[i] = Y[int(sent[k][0])-1]\n",
        "    i+=1\n",
        "    \n",
        "  elif sent[k][1]=='2':\n",
        "    X_val[b] = X[min(11285,int(sent[k][0])-1)]\n",
        "    y_val[b] = Y[int(sent[k][0])-1]\n",
        "    \n",
        "    b+=1\n",
        "  elif sent[k][1]=='3':\n",
        "    X_test[j] = X[min(11285,int(sent[k][0])-1)]\n",
        "    y_test[j] = Y[int(sent[k][0])-1]\n",
        "    j+=1\n",
        "    \n",
        "y_train = y_train.astype(int)\n",
        "y_val = y_val.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "i,b,j"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7980, 2205, 1101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djj47Xf0I5MM",
        "outputId": "020ee87b-1d2e-4f43-e7d9-a0f643787598"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.57058001,  0.44183001,  0.70102   , ..., -0.66101998,\n",
              "         0.47196999,  0.37253001],\n",
              "       [ 0.41051999,  0.058649  ,  0.28514999, ..., -0.37898001,\n",
              "         0.33021   , -0.27462   ],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VaIdsBuuxKP"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten,LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdMKeuvcpn5v"
      },
      "source": [
        "data preparation IMP ---- change the location of sentiment(2) and glove matrix while running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5ExHakFxMMB",
        "outputId": "e84dc3bc-c7b4-45c8-aedb-a90394ef2a06"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f0IS7gJuXuQ",
        "outputId": "225af46b-31ff-4825-b059-30f0adaac0e0"
      },
      "source": [
        "movie_reviews = pd.read_csv(pat+'sentiment (2).csv')\n",
        "movie_reviews.isnull().values.any()\n",
        "movie_reviews.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11286, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oCHXK23qQkw"
      },
      "source": [
        "text preprocessing - removing stop-words, punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gro0CmJuu3SX"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36H-GI63u5Og"
      },
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bl5q6pOqYW2"
      },
      "source": [
        "Tokenizing the words and padding them if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-zhv8LJxHcf"
      },
      "source": [
        "#loading glove vectors\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open(pat+'glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbkyYDw9xdUr"
      },
      "source": [
        "#embedding matrixfor embedding layer\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ps1sQBQqeG1"
      },
      "source": [
        "Model, and the hyperparameter testing code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7C9cMbJGO4p"
      },
      "source": [
        "converting onehot to normal numbers\n",
        "X_tr=np.zeros(X_train.shape[:2])\n",
        "i=0\n",
        "for el in X_train:\n",
        "  j=0\n",
        "  for e in el:\n",
        "    X_tr[i,j]=np.argmax(e)\n",
        "    j+=1\n",
        "  i+=1\n",
        "X_t=np.zeros(X_test.shape[:2])\n",
        "i=0\n",
        "for el in X_test:\n",
        "  j=0\n",
        "  for e in el:\n",
        "    X_t[i,j]=np.argmax(e)\n",
        "    j+=1\n",
        "  i+=1\n",
        "X_v=np.zeros(X_val.shape[:2])\n",
        "i=0\n",
        "for el in X_val:\n",
        "  j=0\n",
        "  for e in el:\n",
        "    X_v[i,j]=np.argmax(e)\n",
        "    j+=1\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5LQHfIQQDhp"
      },
      "source": [
        "#one- hot function\n",
        "def oh(y):\n",
        "  y2=np.zeros([len(y),5])\n",
        "  i=0\n",
        "  for el in y:\n",
        "    y2[i,el]=1\n",
        "    i+=1\n",
        "  return y2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnWvI5qYQU7D",
        "outputId": "4c387c1b-fe32-4ccb-96cf-aed3907a23f3"
      },
      "source": [
        "oh([1,2,3,4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMzXlYUoaL0M"
      },
      "source": [
        "The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D88-jrwZqm0y"
      },
      "source": [
        "model2 = Sequential()\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model2.add(embedding_layer)\n",
        "model2.add(LSTM(128))\n",
        "\n",
        "model2.add(Dense(5, activation='sigmoid'))\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "print(model2.summary())\n",
        "history = model2.fit(X_tr, oh(y_train[:]), batch_size=128, epochs=10, verbose=1, validation_data=[X_v,oh(y_val[:])])\n",
        "score = model2.evaluate(X_t, oh(y_test[:]), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR8dV-ZGaRIy"
      },
      "source": [
        "Testing for hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7SRm00IcAQR"
      },
      "source": [
        "num = [64,128,256,200]     #model running by testing various hyperparameter\n",
        "losses = []\n",
        "for i in num:\n",
        "  model = Sequential()\n",
        "  embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "  model.add(embedding_layer)\n",
        "  model.add(LSTM(i))\n",
        "\n",
        "  model.add(Dense(5, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "  print(model.summary())\n",
        "  history = model.fit(X_tr, oh(y_train[:]), batch_size=128, epochs=10, verbose=1, validation_data=[X_v,oh(y_val[:])])\n",
        "  score = model.evaluate(X_t, oh(y_test[:]), verbose=1)\n",
        "  losses.append(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsOj1Mscygck"
      },
      "source": [
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcDradjtaZNI"
      },
      "source": [
        "Printing the values of train and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNKQWKQpyisU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPA9aEzQaVsT"
      },
      "source": [
        "Code testing, do not run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI3_-8MBSHIo"
      },
      "source": [
        "reviews = df['review']\n",
        "labels = np.array(df['senti_score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2d4j8jPSHIo"
      },
      "source": [
        "for label in range(len(labels)):\n",
        "  if float(labels[label])<=0.2:\n",
        "    labels[label] = 0\n",
        "  elif float(labels[label])<=0.4:\n",
        "    labels[label] = 1\n",
        "  elif float(labels[label])<=0.6:\n",
        "    labels[label] = 2\n",
        "  elif float(labels[label])<=0.8:\n",
        "    labels[label] = 3\n",
        "  elif float(labels[label])<=1.0:\n",
        "    labels[label] = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puvugNRkSHIo"
      },
      "source": [
        "reviews = reviews.str.lower()\n",
        "for i in range(df.shape[0]):\n",
        "  reviews[i] = re.sub(r'[^\\w\\s]', '', reviews[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO_GquSzasKw"
      },
      "source": [
        "Everything is same, for CBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au51FNnlSHIo"
      },
      "source": [
        "a=np.loadtxt(pat+'Movie Review Dataset.txt',delimiter='\\t',dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMaOqPAgSHIo"
      },
      "source": [
        "a2=[]\n",
        "for e1,e2 in a:\n",
        "    a2+=[e2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os5mpTvZSHIo",
        "outputId": "968417ee-95d8-4bdf-cb9b-caed0a71d1b6"
      },
      "source": [
        "len(a2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqDpfRe0SHIo",
        "outputId": "a70d29df-15c6-4480-8e69-467170b75b2d"
      },
      "source": [
        "q2=[] #contains word of sentences\n",
        "q3=[] #contains sentences\n",
        "for e in a2:\n",
        "  f=[]\n",
        "  for el2 in e.split(' '):\n",
        "    f+=[el2.lower()]\n",
        "    \n",
        "  q2+=f\n",
        "  q3+=[f]\n",
        "sen_len=np.array(q2) \n",
        "n=len(np.unique(sen_len))#Vocabulary size\n",
        "n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFqq-xmVSHIo"
      },
      "source": [
        "qwe=np.unique(sen_len)#list of unique words\n",
        "tab=np.zeros([n,n],dtype=np.int32)#coocurrence matrix\n",
        "word_to_num=dict(zip(qwe,range(n)))#dictionary for word to num\n",
        "sen=np.array(q3)\n",
        "data_training = sen[1:]#remove heading"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxDSrY5VSHIo",
        "outputId": "481a05b0-9744-498b-9938-6a5a276782b2"
      },
      "source": [
        "wemb=np.loadtxt(pat+'data3.csv',delimiter=',')\n",
        "wemb.T.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19538, 400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiTe1zSWSHIo",
        "outputId": "b20663c5-eb42-4870-c567-b70a468184d8"
      },
      "source": [
        "len(qwe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWr9FWrgSHIo"
      },
      "source": [
        "embeddings_dictionary=dict(zip(qwe,wemb.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNR0pORXSHIo"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "#glove_file = open('/content/drive/MyDrive/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "wemb=np.loadtxt(pat+'data3.csv',delimiter=',')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czE6S_ztSHIp"
      },
      "source": [
        "maxlen = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U00ZdgHiSHIp"
      },
      "source": [
        "embedding_matrix = np.empty((len(reviews),maxlen,400))\n",
        "j=0\n",
        "k=0\n",
        "k2=0\n",
        "for sent in reviews:\n",
        "  sent_embed = np.empty((maxlen,400))\n",
        "  i=0\n",
        "  for word in sent.split():\n",
        "    if i==maxlen:\n",
        "      break\n",
        "    \n",
        "    try:\n",
        "      sent_embed[i] = np.array(embeddings_dictionary[word]).reshape((1,400))\n",
        "    except KeyError: \n",
        "      sent_embed[i] = np.zeros((1,400))\n",
        "      k+=1\n",
        "    print(sent_embed.shape)\n",
        "    i+=1\n",
        "    k2+=1\n",
        "\n",
        "  if i<maxlen:\n",
        "    padding_matrix = np.zeros((maxlen-i,400))\n",
        "    sent_embed[i:] = padding_matrix\n",
        "  embedding_matrix[j] = sent_embed\n",
        "  j+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBllvbtkSHIp"
      },
      "source": [
        "X = embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOylsHShSHIp"
      },
      "source": [
        "y = np.empty((len(reviews),maxlen))\n",
        "com = np.ones((1,maxlen))\n",
        "i=0\n",
        "for label in labels:\n",
        "  y[i] = np.array(label*com)\n",
        "  i+=1\n",
        "y = y.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WpEz47MSHIp"
      },
      "source": [
        "Y=y[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyOj8wDmSHIp"
      },
      "source": [
        "# fp = open('/content/Train-Dev_test split.txt', 'r')\n",
        "sent=np.loadtxt(pat+'Train-Dev_test split.txt',delimiter=',',dtype=str,skiprows=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YpAmBJdSHIp",
        "outputId": "f50042e6-4df2-4655-d669-190b467a8350"
      },
      "source": [
        "sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['1', '1'],\n",
              "       ['2', '1'],\n",
              "       ['3', '2'],\n",
              "       ...,\n",
              "       ['11853', '1'],\n",
              "       ['11854', '1'],\n",
              "       ['11855', '1']], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ah4oZ8mSHIp"
      },
      "source": [
        "X_train = np.empty((7980,maxlen,400))\n",
        "X_test = np.empty((1101,maxlen,400)) \n",
        "X_val = np.empty((2205,maxlen,400))\n",
        "y_train = np.empty((7980))\n",
        "y_test = np.empty((1101))\n",
        "y_val = np.empty((2205))\n",
        "i=0\n",
        "j=0\n",
        "k=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81WHO5xuSHIp",
        "outputId": "b42b27a2-1886-4a47-c13e-1a932ce40ada"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3. 4. 2. ... 3. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkB0zqjqSHIp",
        "outputId": "a253c02c-aa17-471f-a5d3-cc768eedc6bb"
      },
      "source": [
        "a=0\n",
        "b=0\n",
        "c=0\n",
        "for k in range(len(reviews)):\n",
        "  if sent[k][1]=='1':\n",
        "    X_train[i] = X[min(11285,int(sent[k][0])-1)]\n",
        "    y_train[i] = Y[int(sent[k][0])-1]\n",
        "    i+=1\n",
        "    a+=1\n",
        "  elif sent[k][1]=='2':\n",
        "    X_val[b] = X[min(11285,int(sent[k][0])-1)]\n",
        "    y_val[b] = Y[int(sent[k][0])-1]\n",
        "    \n",
        "    b+=1\n",
        "  elif sent[k][1]=='3':\n",
        "    X_test[j] = X[min(11285,int(sent[k][0])-1)]\n",
        "    y_test[j] = Y[int(sent[k][0])-1]\n",
        "    j+=1\n",
        "    \n",
        "y_train = y_train.astype(int)\n",
        "y_val = y_val.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "i,b,j"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7980, 2205, 1101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh6xJ_orSHIp",
        "outputId": "020ee87b-1d2e-4f43-e7d9-a0f643787598"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.57058001,  0.44183001,  0.70102   , ..., -0.66101998,\n",
              "         0.47196999,  0.37253001],\n",
              "       [ 0.41051999,  0.058649  ,  0.28514999, ..., -0.37898001,\n",
              "         0.33021   , -0.27462   ],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb1AX36USHIp"
      },
      "source": [
        "data preparation IMP ---- change the location of sentiment(2) and glove matrix while running"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9m9cWqpSHIp"
      },
      "source": [
        "text preprocessing - removing stop-words, punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwmnXs2qSHIp"
      },
      "source": [
        "Tokenizing the words and padding them if necessary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xi6Q6ihSHIq"
      },
      "source": [
        "Model, and the hyperparameter testing code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teHLRdLTSHIq"
      },
      "source": [
        "X_tr=np.zeros(X_train.shape[:2])\n",
        "i=0\n",
        "for el in X_train:\n",
        "  j=0\n",
        "  for e in el:\n",
        "    X_tr[i,j]=np.argmax(e)\n",
        "    j+=1\n",
        "  i+=1\n",
        "X_t=np.zeros(X_test.shape[:2])\n",
        "i=0\n",
        "for el in X_test:\n",
        "  j=0\n",
        "  for e in el:\n",
        "    X_t[i,j]=np.argmax(e)\n",
        "    j+=1\n",
        "  i+=1\n",
        "X_v=np.zeros(X_val.shape[:2])\n",
        "i=0\n",
        "for el in X_val:\n",
        "  j=0\n",
        "  for e in el:\n",
        "    X_v[i,j]=np.argmax(e)\n",
        "    j+=1\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2yCxxZcSHIq",
        "outputId": "78c9d43f-d2e1-408e-bb99-8da15dd1e82e"
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Hd1bO9ggSHIq",
        "outputId": "89d363fb-ea0a-4b82-c510-1f5df572b9e5"
      },
      "source": [
        "X_t=np.ndarray(X_t,shape=[1101,32])\n",
        "X_tr=np.array(X_tr)\n",
        "X_v=np.array(X_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-c928146cadf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1101\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Argument given by name ('shape') and position (1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN0s_wFxSHIq",
        "outputId": "ae94ca22-4168-4139-b75f-31436fdba98a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEYis_bTSHIq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Up7KL1dSHIq"
      },
      "source": [
        "err=model2.predict(X_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjR8tlzXSHIq"
      },
      "source": [
        "def oh(y):\n",
        "  y2=np.zeros([len(y),5])\n",
        "  i=0\n",
        "  for el in y:\n",
        "    y2[i,el]=1\n",
        "    i+=1\n",
        "  return y2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFKgoQl8SHIq",
        "outputId": "4c387c1b-fe32-4ccb-96cf-aed3907a23f3"
      },
      "source": [
        "oh([1,2,3,4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l06i_kBGUsn1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq-HiWR_U6d-"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "YGGlBCo3SHIq",
        "outputId": "f940bf5d-d77d-4fcf-f837-29904c5432fc"
      },
      "source": [
        "model2 = Sequential()\n",
        "embedding_layer = Embedding(vocab_size, 400, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model2.add(embedding_layer)\n",
        "model2.add(LSTM(128))\n",
        "\n",
        "model2.add(Dense(5, activation='softmax'))\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
        "print(model2.summary())\n",
        "history = model2.fit(X_tr, oh(y_train[:]), batch_size=128, epochs=100, verbose=1, shuffle=True,validation_data=[X_v,oh(y_val[:])])\n",
        "score = model2.evaluate(X_t, oh(y_test[:]), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-222-f591ba1e8d40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    204\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m           \u001b[0;31m# Using `init_scope` since we want variable assignment in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m           \u001b[0;31m# `set_weights` to be treated like variable initialization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1824\u001b[0m           raise ValueError(\n\u001b[1;32m   1825\u001b[0m               \u001b[0;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1826\u001b[0;31m               'shape %s' % (ref_shape, weight.shape))\n\u001b[0m\u001b[1;32m   1827\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mweight_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer weight shape (15386, 400) not compatible with provided weight shape (15386, 100)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4aFMKpbToLx",
        "outputId": "1f560280-6d5a-4e71-f3ed-b9463f90136e"
      },
      "source": [
        "model2.predict(X_tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13175671, 0.25283512, 0.20003451, 0.263257  , 0.15211672],\n",
              "       [0.13175671, 0.25283512, 0.20003451, 0.263257  , 0.15211672],\n",
              "       [0.13175671, 0.25283512, 0.20003451, 0.263257  , 0.15211672],\n",
              "       ...,\n",
              "       [0.13175671, 0.25283512, 0.20003451, 0.263257  , 0.15211672],\n",
              "       [0.13175671, 0.25283512, 0.20003451, 0.263257  , 0.15211672],\n",
              "       [0.13175671, 0.25283512, 0.20003451, 0.263257  , 0.1521167 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcZUs1hLUlAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}